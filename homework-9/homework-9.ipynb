{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "597ea499-7f57-4d35-9ad0-4404046bd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f539ce-31a3-44e9-9aa5-e630f2b8a93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff828cee-092d-4d98-9a44-4a7d28473aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ead00314-33b9-4e52-99f0-af4eeaef8ca0",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "In this homework, we'll deploy the bees vs wasps model we trained in the \n",
    "[previous homework](../08-deep-learning/homework.md).\n",
    "\n",
    "Download the model from here: \n",
    "\n",
    "https://github.com/alexeygrigorev/large-datasets/releases/download/wasps-bees/bees-wasps.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d15248-2ef6-464e-a715-5a58e66fe517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-26 06:23:17--  https://github.com/alexeygrigorev/large-datasets/releases/download/wasps-bees/bees-wasps.h5\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/05aeef6d-6432-4320-a521-025803848f49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231126%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231126T122318Z&X-Amz-Expires=300&X-Amz-Signature=d7387a152fe1551dfe7e51568e4e0dfbc185af27caabfd3bca486bad7e8c9639&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Dbees-wasps.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-11-26 06:23:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/05aeef6d-6432-4320-a521-025803848f49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231126%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231126T122318Z&X-Amz-Expires=300&X-Amz-Signature=d7387a152fe1551dfe7e51568e4e0dfbc185af27caabfd3bca486bad7e8c9639&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Dbees-wasps.h5&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 89753864 (86M) [application/octet-stream]\n",
      "Saving to: ‘bees_wasps_model.h5’\n",
      "\n",
      "bees_wasps_model.h5 100%[===================>]  85.60M  31.4MB/s    in 2.7s    \n",
      "\n",
      "2023-11-26 06:23:21 (31.4 MB/s) - ‘bees_wasps_model.h5’ saved [89753864/89753864]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/wasps-bees/bees-wasps.h5 -O bees_wasps_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29690000-dc49-46de-8889-f587bb46c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 06:25:47.163119: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-26 06:25:47.163173: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-26 06:25:47.163187: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-26 06:25:47.163741: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-26 06:25:47.164115: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('bees_wasps_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a15c40-2a7b-4716-a75b-feb3604e91c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/v9/93rc7dfs375c0pyff8wx6c6h0000gn/T/tmpc8g8_ijq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/v9/93rc7dfs375c0pyff8wx6c6h0000gn/T/tmpc8g8_ijq/assets\n",
      "2023-11-26 06:29:18.906266: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-11-26 06:29:18.906288: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-11-26 06:29:18.907911: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/v9/93rc7dfs375c0pyff8wx6c6h0000gn/T/tmpc8g8_ijq\n",
      "2023-11-26 06:29:18.908404: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-11-26 06:29:18.908408: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/v9/93rc7dfs375c0pyff8wx6c6h0000gn/T/tmpc8g8_ijq\n",
      "2023-11-26 06:29:18.909970: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-11-26 06:29:18.910493: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-11-26 06:29:19.034623: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/v9/93rc7dfs375c0pyff8wx6c6h0000gn/T/tmpc8g8_ijq\n",
      "2023-11-26 06:29:19.039679: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 131768 microseconds.\n",
      "2023-11-26 06:29:19.059786: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# converting the keras model to smaller tflite version\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c79b870-21c6-4787-83fb-844fabd24659",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bees_wasps_tflite.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48889468-016e-4091-95de-d19d280acdf5",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Now convert this model from Keras to TF-Lite format.\n",
    "\n",
    "What's the size of the **converted** model?\n",
    "\n",
    "* 21 Mb\n",
    "* 43 Mb\n",
    "* 80 Mb\n",
    "* 164 Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc599cbd-8fcd-46a5-b4d0-8fbbe12b2644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 285136\n",
      "-rw-r--r--  1 isaachurwitz  staff    15K Nov 26 06:29 Untitled.ipynb\n",
      "-rw-r--r--  1 isaachurwitz  staff    86M Nov 17 15:51 bees_wasps_model.h5\n",
      "-rw-r--r--  1 isaachurwitz  staff    43M Nov 26 06:30 bees_wasps_tflite.tflite\n",
      "drwxr-xr-x  2 isaachurwitz  staff    64B Nov 26 06:13 \u001b[34mdata\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b9911-7e78-4983-8eb6-340771c3b9f7",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "To be able to use this model, we need to know the index of the input and \n",
    "the index of the output. \n",
    "\n",
    "What's the output index for this model?\n",
    "\n",
    "* 3\n",
    "* 7\n",
    "* 13\n",
    "* 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68239ef-f623-4974-9e17-f8158d574bf4",
   "metadata": {},
   "source": [
    "answer: 43 Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec02a0ae-6d06-4486-abcc-54d1bc54b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the 2022 homework\n",
    "# interpreter = tflite.Interpreter(model_path='bees_wasps_tflite.tflite')\n",
    "# interpreter.allocate_tensors()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path='bees_wasps_tflite.tflite')  # Replace with the actual filename of your TFLite model\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f996640-d0b8-4743-950e-3965317a47c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80124924-bc77-4209-b323-059453182738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1622c7-2530-4990-be05-4e758c4cc535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e247315-a752-4d06-9eac-1d2f65087d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      "Input 0: serving_default_conv2d_input:0 (dtype=<class 'numpy.float32'>, shape=[  1 150 150   3])\n",
      "\n",
      "Output details:\n",
      "Output 0: StatefulPartitionedCall:0 (dtype=<class 'numpy.float32'>, shape=[1 1])\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path='bees_wasps_tflite.tflite')  # Replace with the actual filename of your TFLite model\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# # Load the TFLite model\n",
    "# interpreter = tf.lite.Interpreter(model_path='your_model.tflite')  # Replace with the actual filename of your TFLite model\n",
    "# interpreter.allocate_tensors()\n",
    "\n",
    "# Get the input details\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Get the output details\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Print information about the inputs\n",
    "print(\"Input details:\")\n",
    "for i, inp in enumerate(input_details):\n",
    "    print(f\"Input {i}: {inp['name']} (dtype={inp['dtype']}, shape={inp['shape']})\")\n",
    "\n",
    "# Print information about the outputs\n",
    "print(\"\\nOutput details:\")\n",
    "for i, output in enumerate(output_details):\n",
    "    print(f\"Output {i}: {output['name']} (dtype={output['dtype']}, shape={output['shape']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57989f93-c314-40ef-ba88-d19c371407c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 13,\n",
       "  'shape': array([1, 1], dtype=int32),\n",
       "  'shape_signature': array([-1,  1], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e10943-2b75-4144-abed-62f9479ab7dd",
   "metadata": {},
   "source": [
    "answer: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f8976a-17c1-4fc4-a664-c5238a98093a",
   "metadata": {},
   "source": [
    "## Preparing the image\n",
    "\n",
    "You'll need some code for downloading and resizing images. You can use \n",
    "this code:\n",
    "\n",
    "```python\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ea4cb6-c479-4f58-bf91-ecf1648042a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262c534-f20d-4392-8c6a-43c2e3c96bea",
   "metadata": {},
   "source": [
    "For that, you'll need to have `pillow` installed:\n",
    "\n",
    "```bash\n",
    "pip install pillow\n",
    "```\n",
    "\n",
    "Let's download and resize this image: \n",
    "\n",
    "https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\n",
    "\n",
    "Based on the previous homework, what should be the target size for the image?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f4776f-7b4c-45a2-91bf-4078e669f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the image\n",
    "\n",
    "url = 'https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg'\n",
    "image = download_image(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af46cd9-ce0b-4aa5-8871-eb7f40e4795b",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now we need to turn the image into numpy array and pre-process it. \n",
    "\n",
    "> Tip: Check the previous homework. What was the pre-processing \n",
    "> we did there?\n",
    "\n",
    "After the pre-processing, what's the value in the first pixel, the R channel?\n",
    "\n",
    "* 0.3450980\n",
    "* 0.5450980\n",
    "* 0.7450980\n",
    "* 0.9450980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83f5f10d-37d9-4df9-9979-96d846c9060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = prepare_image(image, target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09fcd555-b480-4a58-933a-de03d4dc5cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1400dd0e-1c10-465a-aa90-6d6cbc018991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(x):\n",
    "    return x / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca9136db-ddcb-4286-86bf-c5035a67ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(image, dtype='float32')\n",
    "X = np.array([x])\n",
    "X = prepare_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab0f247e-fef5-4ab9-a53c-596b757d9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(image)\n",
    "x = np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a361f04-1f4f-4c01-b375-551d7218ddda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150, 150, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b67772d7-8d6f-458f-a8d7-a5f6a4619ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94509804, 0.9098039 , 0.8509804 ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27d273-7a1e-4149-a1fd-87faa27e3a07",
   "metadata": {},
   "source": [
    "answer: 0.9450980"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c818700-1caa-4006-9885-5a1d6f5f8508",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4\n",
    "\n",
    "Now let's apply this model to this image. What's the output of the model?\n",
    "\n",
    "* 0.258\n",
    "* 0.458\n",
    "* 0.658\n",
    "* 0.858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d77e292-f730-45c0-ad51-f33330e1c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b67bde28-a23e-48f8-81fd-36a0518de83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65921456]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86026a3c-3e92-49d0-86e9-8a6a198bd30a",
   "metadata": {},
   "source": [
    "answer: 0.658"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc6292-b482-410c-947f-6655061acefc",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Download the base image `agrigorev/zoomcamp-bees-wasps:v2`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "* 162 Mb\n",
    "* 362 Mb\n",
    "* 662 Mb\n",
    "* 962 Mb\n",
    "\n",
    "You can get this information when running `docker images` - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa69ff-8820-444d-832a-9b4b9b45900e",
   "metadata": {},
   "source": [
    "I used the command \n",
    "```docker image ls```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6beb3d1-80a5-46b8-9784-5fcad5ff81b3",
   "metadata": {},
   "source": [
    "answer: 662mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e844c-c06d-411b-8a3a-821693780bb5",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's extend this docker image, install all the required libraries\n",
    "and add the code for lambda.\n",
    "\n",
    "You don't need to include the model in the image. It's already included. \n",
    "The name of the file with the model is `bees-wasps-v2.tflite` and it's \n",
    "in the current workdir in the image (see the Dockerfile above for the \n",
    "reference). \n",
    "The provided model requires the same preprocessing for images regarding target size and rescaling the value range than used in homework 8.\n",
    "\n",
    "Now run the container locally.\n",
    "\n",
    "Score this image: https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\n",
    "\n",
    "What's the output from the model?\n",
    "\n",
    "* 0.2453\n",
    "* 0.4453\n",
    "* 0.6453\n",
    "* 0.8453"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856fe87-3cb0-4691-8c89-a721f9a85019",
   "metadata": {},
   "source": [
    "```docker build -t bees-wasps .```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abd925-5ba5-4eb9-b8f7-16e25b33aacb",
   "metadata": {},
   "source": [
    "answer: 0.4453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1433a-c7e0-47e6-94df-3ed58157f63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25e0c3-de26-4b65-bcd4-5c0a19e01743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a35ed-4ae4-474a-962b-6963ba88fefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635332b-e8d1-4497-9606-36083a2a7dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6eba9f-9a62-45f4-9be7-b4ab6ac4391b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d5c18b-6d81-44b5-9caa-56fceb690e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df271f9-67fd-4f62-b7f5-0b81404dae02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38537abd-cdfa-4a83-89eb-5194aebb0836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow-2)",
   "language": "python",
   "name": "tensorflow-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
