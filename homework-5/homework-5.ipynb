{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb5c108-0e40-4a2b-bca5-b7cf34efa934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9985ea-3392-459a-b477-c3012592bbd2",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install Pipenv\n",
    "* What's the version of pipenv you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2792156-3b85-4386-8faf-d07c8026a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mpipenv\u001b[0m, version 2023.7.4\r\n"
     ]
    }
   ],
   "source": [
    "!pipenv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf18f0-da5f-4db4-81bd-a5efdf4c5fd1",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use Pipenv to install Scikit-Learn version 1.3.1\n",
    "* What's the first hash for scikit-learn you get in Pipfile.lock?\n",
    "\n",
    "> **Note**: you should create an empty folder for homework\n",
    "and do it there. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91fe920-559e-4dc0-aa85-9cd8826df56c",
   "metadata": {},
   "source": [
    "answer: sha256:0c275a06c5190c5ce00af0acbb61c06374087949f643ef32d355ece12c4db043"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbb531-52e4-4033-9d5b-0887617ffc8b",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "features = ['job','duration', 'poutcome']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression().fit(X, y)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "\n",
    "* [DictVectorizer](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/model1.bin?raw=true)\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b68d5-cdd1-434d-841b-197e59639fde",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this client:\n",
    "\n",
    "```json\n",
    "{\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit? \n",
    "\n",
    "* 0.162\n",
    "* 0.392\n",
    "* 0.652\n",
    "* 0.902\n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum model1.bin dv.bin\n",
    "3f57f3ebfdf57a9e1368dcd0f28a4a14  model1.bin\n",
    "6b7cded86a52af7e81859647fa3a5c2e  dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3864baf7-d4f8-43dd-b850-b8ae53f4512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8ebfdf20010cfc7f545c43e3b52fc8a1  model1.bin\r\n",
      "924b496a89148b422c74a62dbc92a4fb  dv.bin\r\n"
     ]
    }
   ],
   "source": [
    "!md5sum model1.bin dv.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d38896-7c7a-47cb-91b7-5c1b6fcf844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Open the file in binary read mode\n",
    "with open('model1.bin', 'rb') as f_out1:\n",
    "    # Load the pickled object (your model) from the file\n",
    "    model = pickle.load(f_out1)\n",
    "    \n",
    "with open('dv.bin', 'rb') as f_out2:\n",
    "    # Load the pickled object (your model) from the file\n",
    "    dv = pickle.load(f_out2)    \n",
    "\n",
    "# client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "# client = dv.transform(client)\n",
    "# pred = model.predict_proba(client)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a11832ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90193093])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "client = dv.transform(client)\n",
    "pred = model.predict_proba(client)[:, 1]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de472924",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit?\n",
    "\n",
    "* 0.140\n",
    "* 0.440\n",
    "* 0.645\n",
    "* 0.845\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6acc7",
   "metadata": {},
   "source": [
    "answer: clostest was 0.14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd0956",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/05-deployment/06-docker.md). \n",
    "We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `svizor/zoomcamp-model:3.10.12-slim`. \n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `python:3.10.12-slim` and has a logistic regression model \n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.10.12-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to [`svizor/zoomcamp-model:3.10.12-slim`](https://hub.docker.com/r/svizor/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference.\n",
    "\n",
    "\n",
    "## Question 5\n",
    "\n",
    "Download the base image `svizor/zoomcamp-model:3.10.12-slim`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "* 47 MB\n",
    "* 147 MB\n",
    "* 374 MB\n",
    "* 574 MB\n",
    "\n",
    "You can get this information when running `docker images` - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90dac8",
   "metadata": {},
   "source": [
    "these are the commands i used to get this info\n",
    "- docker pull svizor/zoomcamp-model:3.10.12-slim\n",
    "- docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcb7ea",
   "metadata": {},
   "source": [
    "answer: 147MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe643488",
   "metadata": {},
   "source": [
    "## Dockerfile\n",
    "\n",
    "Now create your own Dockerfile based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "```docker\n",
    "FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "# add your stuff here\n",
    "```\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies form the Pipenv file\n",
    "* Copy your Flask script\n",
    "* Run it with Gunicorn \n",
    "\n",
    "After that, you can build your docker image.\n",
    "\n",
    "\n",
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit now?\n",
    "\n",
    "* 0.168\n",
    "* 0.530\n",
    "* 0.730\n",
    "* 0.968\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43ca67",
   "metadata": {},
   "source": [
    "commands I ran to answer questoin:\n",
    "\n",
    "- docker build -t hw-5:latest .\n",
    "-  docker run -it -p 9696:9696 hw-5:latest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bdb2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer: .1682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45180d6d-9e9e-4331-a67e-9742b12815f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aafc720-671e-420f-9886-b23c08340459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.3.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "# Check if scikit-learn is installed and print its version\n",
    "if 'sklearn' in sklearn.__doc__:\n",
    "    print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "else:\n",
    "    print(\"scikit-learn is not installed in this environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db92443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isaachurwitz/.local/share/virtualenvs/homework-5-5NStlO2L/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f4895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/isaachurwitz/mlc/2023/homework-5', '/Users/isaachurwitz/opt/anaconda3/envs/hw-5-2023/lib/python310.zip', '/Users/isaachurwitz/opt/anaconda3/envs/hw-5-2023/lib/python3.10', '/Users/isaachurwitz/opt/anaconda3/envs/hw-5-2023/lib/python3.10/lib-dynload', '', '/Users/isaachurwitz/.local/share/virtualenvs/homework-5-5NStlO2L/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ffec7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homework-5",
   "language": "python",
   "name": "homework-5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
